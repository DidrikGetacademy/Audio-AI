###############################################################TRAIN################################################################


""""""""HYPER-PARAMETERS"""""""
learning_rate: 

batch_size: 

epochs:




"""""""""DATASET PARAMETERS"""""
sr:

n_fft:

hop_length:

max_length:

max_files:



""""""DATALOADER PARAMETERS"""""""
dataset:

batch_size:

Shuffle:

num_workers:

pin_memory:












""""""""""""RUNNING THE FILE"""""""""""""""
Device cuda
Loaded model from C:\Users\didri\Desktop\AI AudioEnchancer\UNet_Model\unet_vocal_isolation.pth
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Epoch [1/3], Loss: 3.4725
Epoch [1/3], Validation Loss: 3.3963
Checkpoint saved for epoch 1 at C:\Users\didri\Desktop\AI AudioEnchancer\UNet_Model\CheckPoints\unet_checkpoint_epoch1.pth
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Epoch [2/3], Loss: 2.6523
Epoch [2/3], Validation Loss: 2.1109
Checkpoint saved for epoch 2 at C:\Users\didri\Desktop\AI AudioEnchancer\UNet_Model\CheckPoints\unet_checkpoint_epoch2.pth
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Input shape: torch.Size([2, 1, 513, 10000]), Target shape: torch.Size([2, 1, 513, 10000])
Epoch [3/3], Loss: 2.2240
Epoch [3/3], Validation Loss: 1.8147
Checkpoint saved for epoch 3 at C:\Users\didri\Desktop\AI AudioEnchancer\UNet_Model\CheckPoints\unet_checkpoint_epoch3.pth
Training complete. Model saved.
Evaluating the model on the test set...
Test Loss: 1.8147
Testing complete.
PS C:\Users\didri\Desktop\AI AudioEnchancer> 



SUMMARY: 